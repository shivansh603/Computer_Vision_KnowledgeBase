Computer Vision Task: Efficient Image Classification
Model Name: MobileViT
Model Architecture: Transformer-based Neural Network with Inverted Residual Blocks
Description: MobileViT is an efficient variant of the Vision Transformer architecture, designed for mobile and resource-constrained devices. It introduces a novel attention mechanism that combines the strengths of Transformers and Convolutional Neural Networks (CNNs). MobileViT replaces the standard multi-head self-attention blocks with lightweight inverted residual blocks, which significantly reduces computational complexity while maintaining the long-range dependency modeling capabilities of Transformers.
Metrics:

Top-1 Accuracy: 78.4% (on ImageNet-1K)
Top-5 Accuracy: 94.1% (on ImageNet-1K)
Inference Time: 5 ms per image on NVIDIA Jetson AGX Xavier

Dependencies:

Software Dependencies: PyTorch, TensorFlow, OpenCV, NumPy, Pillow
Hardware Requirements: GPU (NVIDIA Jetson AGX Xavier or similar recommended), CPU

Limitations:

Performance may be lower compared to the standard ViT on larger datasets or more complex tasks.
Trade-off between efficiency and accuracy, depending on the specific resource constraints.

References / Source:

https://arxiv.org/abs/2104.05707
https://github.com/google-research/vision_transformer